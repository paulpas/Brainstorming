
## Sprintâ€¯2 â€“ From Raw Data to Actionable Signals  

Sprintâ€¯2 picks up where Sprintâ€¯1 left off: we now have **clean, timeâ€‘aligned data** (candles, news, tweets) flowing into TimescaleDB.  
The goal of this sprint is to **turn that data into quantitative features, enrich it with LLMâ€‘derived insights, and build a lightweight decision engine** that can be backâ€‘tested and later deployed in realâ€‘time.

At the end of Sprintâ€¯2 you should have:

| âœ… | Deliverable |
|----|-------------|
| 1 | **Technicalâ€‘indicator materialisation** in TimescaleDB (continuous aggregates). |
| 2 | **Sentiment & embedding pipelines** that turn news/tweets into numeric vectors stored alongside candles. |
| 3 | **Retrievalâ€‘augmented LLM reasoner** (prompt + RAG) that returns a biasâ€¯+â€¯confidence JSON for a given symbol/time. |
| 4 | **Hybrid decision model** (quantitative + LLM) that outputs a tradeâ€‘signal probability. |
| 5 | **Backâ€‘testing harness** that reâ€‘plays the whole pipeline on historical data and produces performance metrics. |
| 6 | **Full unitâ€‘test & integrationâ€‘test suite** for every new component, plus CI coverage >â€¯80â€¯%. |
| 7 | Updated documentation and a â€œrunâ€‘allâ€‘inâ€‘Dockerâ€ script for the endâ€‘toâ€‘end pipeline. |

Below is a **taskâ€‘byâ€‘task breakdown** (â‰ˆâ€¯2â€¯weeks of work for a small team). Each task lists a concrete â€œDoneâ€ criterion and suggested unitâ€‘test ideas.

---

## 1ï¸âƒ£ Materialise Technical Indicators (TimescaleDB Continuous Aggregates)

| # | Subâ€‘task | Doneâ€‘criterion | Unitâ€‘test |
|---|----------|----------------|-----------|
| 1.1 | Write SQL functions that compute EMA, RSI, MACD, Bollinger Bands on the `price_candle` hypertable (using `timescaledb_experimental` or PL/pgSQL). | `SELECT * FROM ema_5m('BTC-USD', now() - interval '1 day') LIMIT 1` returns a numeric value. | `test_indicator_sql.py` â€“ spin up a testcontainersâ€‘Postgres, load a few candle rows, run the function, compare against a reference `pandas_ta` calculation. |
| 1.2 | Create **continuous aggregates** (materialised views) for each indicator with a 5â€‘minute refresh policy. | `\d+ ema_5m_view` shows a hypertable with `refresh_lag = '5 minutes'`. | `test_continuous_aggregate_refresh.py` â€“ insert a new candle, wait 6â€¯min (or fastâ€‘forward time with `pg_sleep`), assert the view reflects the new value. |
| 1.3 | Add **indexing** on `(symbol, time_bucket)` for fast lookâ€‘ups. | `EXPLAIN ANALYZE SELECT * FROM ema_5m_view WHERE symbol='BTC-USD' AND time > now() - interval '1 hour'` shows an index scan. | `test_indicator_index.py` â€“ verify query plan contains `Bitmap Index Scan`. |
| 1.4 | Write a **Python wrapper** (`indicator_store.py`) that fetches the latest indicator row for a symbol and returns a dict. | `get_latest_indicators('BTC-USD')` returns `{'ema':â€¦, 'rsi':â€¦, 'macd_hist':â€¦}`. | `test_indicator_wrapper.py` â€“ mock `asyncpg` connection, assert dict keys/types. |

---

## 2ï¸âƒ£ Sentiment & Embedding Pipelines

| # | Subâ€‘task | Doneâ€‘criterion | Unitâ€‘test |
|---|----------|----------------|-----------|
| 2.1 | **Text normalisation** utility (`clean_text.py`): strip URLs, emojis, markdown, lowerâ€‘case, keep only ASCII letters. | `clean_text("ğŸš€ BTC up! https://t.co/xyz")` â†’ `"btc up"` | `test_clean_text.py`. |
| 2.2 | **Embedding generation** â€“ integrate `sentenceâ€‘transformers` (`allâ€‘MiniLMâ€‘L6â€‘v2`) to turn each news/tweet into a 384â€‘dim vector. Store the vector as a `BYTEA` column (`embedding`) in `news_item` / `tweet`. | After ingesting a sample tweet, the DB row contains a nonâ€‘null `embedding` of length 384. | `test_embedding_generation.py` â€“ mock a tweet, run `embed_text()`, assert shape and dtype. |
| 2.3 | **Sentiment scoring** â€“ fineâ€‘tune a small DistilBERT classifier on a cryptoâ€‘sentiment dataset (or use a preâ€‘trained model). Store a float `sentiment_score` âˆˆâ€¯[-1,â€¯1]. | `SELECT sentiment_score FROM news_item WHERE id=â€¦` returns a value between -1 and 1. | `test_sentiment_classifier.py` â€“ feed a knownâ€‘positive headline, assert score >â€¯0.5. |
| 2.4 | **Temporal aggregation** â€“ create a materialised view `news_sentiment_5m(symbol, bucket_start)` that computes `AVG(sentiment_score)` and `COUNT(*)` per 5â€‘minute bucket. | Query returns one row per bucket with `avg_sentiment` and `cnt`. | `test_sentiment_aggregate.py`. |
| 2.5 | **Embedding clustering** â€“ nightly job runs Kâ€‘means (kâ‰ˆ10) on the dayâ€™s embeddings, stores cluster centroids in a table `embedding_cluster`. Each news/tweet gets a `cluster_id`. | After the job, every row in `news_item` has a nonâ€‘null `cluster_id`. | `test_embedding_clustering.py` â€“ run on a tiny synthetic dataset, verify cluster IDs are assigned. |

---

## 3ï¸âƒ£ Retrievalâ€‘Augmented LLM Reasoner (RAG)

| # | Subâ€‘task | Doneâ€‘criterion | Unitâ€‘test |
|---|----------|----------------|-----------|
| 3.1 | **Prompt template** â€“ store a Jinja2 template (see Sprintâ€¯1 description) that expects a JSON blob and asks for biasâ€¯+â€¯confidence. | Template renders without errors given a sample dict. | `test_prompt_render.py`. |
| 3.2 | **RAG service** (`llm_reasoner.py`) that: <br>1. Pulls the latest candle + indicators (from 1.4). <br>2. Pulls the latest sentiment aggregates (from 2.4). <br>3. Pulls the topâ€‘N recent news/tweets (by `published_at`). <br>4. Builds the JSON payload, calls the LLM, parses the JSON response. | `await get_reason('BTC-USD')` returns `{'bias':'UP','confidence':0.81,'rationale':â€¦}`. | `test_llm_reasoner_mock.py` â€“ mock the OpenAI/Anthropic API to return a fixed JSON, assert parsing. |
| 3.3 | **Caching layer** â€“ store the LLM output in Redis with a TTL of 30â€¯s keyed by `symbol:timestamp`. Subsequent calls within the TTL return the cached result. | Two consecutive calls within 10â€¯s hit Redis (log shows â€œcache hitâ€). | `test_llm_cache.py` â€“ use a fake Redis client, assert `get` called before `api`. |
| 3.4 | **Fallback path** â€“ if the LLM call fails (timeout, rateâ€‘limit, or malformed JSON), return `{'bias':'NEUTRAL','confidence':0.0}` and log the incident. | Simulated API error leads to neutral output, no exception bubbles up. | `test_llm_fallback.py`. |
| 3.5 | **Rateâ€‘limit handling** â€“ read `xâ€‘rateâ€‘limitâ€‘remaining` header; if <â€¯5, backâ€‘off exponentially and retry up to 3 times. | When the mock header reports 0, the client sleeps and retries, then succeeds. | `test_llm_rate_limit.py`. |

---

## 4ï¸âƒ£ Hybrid Decision Engine (Quant + LLM)

| # | Subâ€‘task | Doneâ€‘criterion | Unitâ€‘test |
|---|----------|----------------|-----------|
| 4.1 | **Quantitative model** â€“ train a Gradientâ€‘Boosted Tree (XGBoost) on the technical indicators + sentiment aggregates to predict a binary â€œpriceâ€‘upâ€‘inâ€‘Î”tâ€ label. Save the model as `quant_model.pkl`. | `predict_quant(['BTC-USD', â€¦])` returns a probability `p_q âˆˆ [0,1]`. | `test_quant_model.py` â€“ load a preâ€‘saved model, feed a synthetic feature vector, assert output shape. |
| 4.2 | **Metaâ€‘learner** â€“ logistic regression (or shallow MLP) that takes three inputs: `p_q`, `llm_confidence`, and oneâ€‘hot encoded `bias` (UP/DOWN/NEUTRAL). Train on the last 30â€¯days of backâ€‘tested data. Save as `meta_model.pkl`. | `predict_final(features)` returns `p_f`. | `test_meta_learner.py` â€“ mock inputs, assert probability range and that bias encoding works. |
| 4.3 | **Decision rule** â€“ implement a function `signal(p_f, bias, confidence)` that returns `BUY`, `SELL`, or `HOLD` based on thresholds (e.g., `p_f > 0.65 â†’ BUY`). | Unit test verifies each branch with boundary values. | `test_signal_logic.py`. |
| 4.4 | **API endpoint** (`/signal/<symbol>`) that returns the full JSON: `{bias, confidence, p_quant, p_final, decision, rationale}`. | `curl http://localhost:8000/signal/BTC-USD` returns a 200 JSON with all fields. | `test_signal_endpoint.py` â€“ spin up FastAPI test client, mock model predictions, assert response schema. |
| 4.5 | **Modelâ€‘version endpoint** (`/model-info`) that reports timestamps and git SHA for reproducibility. | Returns JSON with `quant_model_version`, `meta_model_version`. | `test_model_info.py`. |

---

## 5ï¸âƒ£ Backâ€‘Testing Harness

| # | Subâ€‘task | Doneâ€‘criterion | Unitâ€‘test |
|---|----------|----------------|-----------|
| 5.1 | **Historical data loader** â€“ a script that pulls candle + indicator + sentiment data for a given date range from TimescaleDB and builds a Pandas DataFrame aligned on 5â€‘minute bars. | `load_history('2023â€‘01â€‘01','2023â€‘01â€‘31')` returns a DataFrame with no NaNs (except at the very start). | `test_history_loader.py`. |
| 5.2 | **LLM replay** â€“ batchâ€‘process the historical timestamps through the RAG service (use the cachedâ€‘mode to avoid real API calls). Store the LLM outputs in a temporary table `llm_replay`. | After running, `SELECT COUNT(*) FROM llm_replay` equals the number of bars. | `test_llm_replay.py` â€“ mock the LLM call to return deterministic outputs, assert row count. |
| 5.3 | **Signal generation** â€“ run the hybrid decision engine on each bar, produce a column `signal` (BUY/SELL/HOLD). | DataFrame now has a `signal` column with only the three allowed values. | `test_signal_generation.py`. |
| 5.4 | **Positionâ€‘sizing & P&L calculator** â€“ simple risk model (1â€¯% of equity per trade, stopâ€‘loss = 1â€¯Ã—â€¯ATR, TP = 2â€¯Ã—â€¯ATR). Compute equity curve. | Plot (`matplotlib`) shows a nonâ€‘flat equity curve; final return >â€¯0% on a test dataset. | `test_pnl_calculator.py` â€“ feed a tiny synthetic series where a BUY is always profitable, assert final equity = initial * (1+gain). |
| 5.5 | **Performance metrics** â€“ compute CAGR, Sharpe, Sortino, maxâ€‘drawdown, winâ€‘rate, profitâ€‘factor. Export a JSON report (`backtest_report.json`). | JSON contains all required keys with numeric values. | `test_backtest_report.py`. |
| 5.6 | **Visualization notebook** â€“ Jupyter notebook that loads `backtest_report.json` and plots equity curve, drawâ€‘down, and signal heatmap. | Notebook runs endâ€‘toâ€‘end without manual edits. | Not a unit test, but include a sanityâ€‘check script that runs `nbconvert --execute`. |

---

## 6ï¸âƒ£ Testing, CI & Documentation

| # | Subâ€‘task | Doneâ€‘criterion |
|---|----------|----------------|
| 6.1 | **Add pytestâ€‘asyncio** to the CI matrix for all async components. |
| 6.2 | **Coverage** â€“ enforce `coverage run -m pytest && coverage report -m` â‰¥â€¯80â€¯% (exclude integrationâ€‘only scripts). |
| 6.3 | **Integration test** (`tests/integration/test_end_to_end.py`) that spins up Dockerâ€‘Compose, runs the full pipeline for a 10â€‘minute window, then checks that the backâ€‘test report file exists and contains a nonâ€‘null `cagr`. |
| 6.4 | **Documentation** â€“ update `README.md` with sections: <br>â€¢ â€œRun the full pipeline (Docker)â€, <br>â€¢ â€œHow to retrain the modelsâ€, <br>â€¢ â€œInterpret the backâ€‘test reportâ€. |
| 6.5 | **Runâ€‘all script** (`run_all.sh`) that: <br>1. `docker compose up -d` <br>2. Wait for DB & Kafka health <br>3. Launch the ingestion services (Coinbase, News, Twitter) <br>4. Launch the RAG + decision service <br>5. Execute the backâ€‘test script <br>6. Print a summary table. |
| 6.6 | **Killâ€‘switch** (`stop_all.sh`) that gracefully stops all containers and removes temporary volumes. |

---

## 7ï¸âƒ£ Timeline (2â€¯Weeks)

| Day | Focus |
|-----|-------|
| **Dayâ€¯1â€‘2** | Indicator SQL functions + continuous aggregates (Taskâ€¯1). |
| **Dayâ€¯3â€‘4** | Sentiment & embedding pipelines (Taskâ€¯2). |
| **Dayâ€¯5** | RAG prompt & LLM wrapper (Taskâ€¯3.1â€‘3.3). |
| **Dayâ€¯6** | LLM fallback, caching, rateâ€‘limit handling (Taskâ€¯3.4â€‘3.5). |
| **Dayâ€¯7** | Quantitative model training & metaâ€‘learner (Taskâ€¯4). |
| **Dayâ€¯8** | API endpoints for signal & model info (Taskâ€¯4.4â€‘4.5). |
| **Dayâ€¯9** | Backâ€‘testing data loader & LLM replay (Taskâ€¯5.1â€‘5.3). |
| **Dayâ€¯10** | P&L calculator, performance metrics (Taskâ€¯5.4â€‘5.5). |
| **Dayâ€¯11** | Unitâ€‘test implementation for all new modules. |
| **Dayâ€¯12** | Integration test, CI pipeline update, coverage check. |
| **Dayâ€¯13** | Documentation, `run_all.sh` / `stop_all.sh`. |
| **Dayâ€¯14** | Buffer / bugâ€‘fix day, sprint demo preparation. |

---

## 8ï¸âƒ£ Sprintâ€‘2 Demo Checklist

- **Live dashboard** (Grafana) showing the latest technical indicators and sentiment aggregates.  
- **REST call** `GET /signal/BTC-USD` returning a fresh LLMâ€‘augmented decision.  
- **Backâ€‘test report** (JSON + plotted equity curve) for the last 30â€¯days, with key metrics displayed.  
- **All unit & integration tests** passing in CI.  

Once the demo is approved, Sprintâ€¯3 can focus on **riskâ€‘management, orderâ€‘execution guard, liveâ€‘trading loop, and advanced reinforcementâ€‘learning / multiâ€‘LLM ensembles**.

Good luck, and happy coding! ğŸš€
